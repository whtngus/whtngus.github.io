---
layout: post
title: "voice - wikidocs"
date: 2020-08-05 19:20:23 +0900
category: datascience
---

# 블로그 내용중 필요해 보이는것만 따로 추출하여 정리

## 원본 책 

책 : 음성인식으로 시작하는 딥러닝 <br>
url : https://wikidocs.net/book/2553

#### 1-1-1 소리의 분류

```
소리는 음성과 음향으로 이루어져 있다.

음성 : 사람이 조음 기관을 사용하여 뜻을 전달하기 위해 의도적으로 만들어낸 소리
음향 : 배경에 존재하는 다양한 소리
``` 

#### 1-1-2 음성의 구성

```
음성은 음소의 합

대사 <- 문장들  : 문장 <- 주어부와 술어부 : 부 <- 구와 단어들 : 단어 <- 음절들 :음절 <- 음소(Phoneme)들 

    - 음운론 
음운론은 음소론과 운소론으로 구별할 수 있다.
- 음소론 : 음소의 구분과 기능을 다룸
음소가 바뀌면 음절과 단어가 다른 뜻이 될 수 있다 -> 변별적 특징(distinctive features)
분류 특징, 후두 특징, 방법 특징, 위치 특징과 같은 자연 분류가 가능
- 운소론 : 음절 구조, 악센트, 억양, 성조 등 음소를 표현하는 방법을 다룸

    - 음소 배열론
자음과 모음의 결합으로 소리가 결합되는 단어를 이루는 규칙을 다룬다. 
```

## 1. 음성인식 구조

#### 1-1-3 음성인식과 신호처리

```
음성처리분야는 다음과 같은 3가지 분야로 나뉜다.
1. 음성코딩
2. 음성인식
3. 음성합성

    - 음성코딩
음성 신호를 효율적으로 전송 및 저장하기 위한 코딩을 연구
아날로그 신호를 디지털 신호르 변환하기 위해 코덱을 사용(LPC, WLPC, A-law, ...)
    - 음성인식
사람이 말하는 음성 언어를 기계가 인식 및 해석하는 기술
문장 인식과, 화자인식 두가지 분야로 나뉘어 있음
주요 알고리즘 : HMM, 동적시간외곡(DTW), 신경망등의 방법이 있음
화자인식에 사용되는 주요 알고리즘 : GMM(Gaussian Mixture Model)과 SVM
    - 음성합성
말소리의 음소를 기계가 자동으로 만들어 내는 기술
텍스트를 음성으로 변환  및 음색변환 이 있다.
```

## 2. 음성인식 시스템 구조

#### 2-1 음성인식 시스템 기본 구조

```
- 음성인식 시스템은 음성신호를 받아서 문장의 형태로 산출하는 역할을 한다.
- 전처리, 패턴 인식, 후처리의 3단계가 필요하다.

    - 전처리
음성 신호로부터 시간 및 주파수 영역의 특징을 추출해 내는 과정
음성 신호의 주기성과 동기성의 정보를 끄집어 낸다.
(청각의 와우각(달팽이관) 기능을 함.) 
    - 패턴 인식
전처리를 통해 얻어낸 특징을 바탕으로, 문장을 구성하는데 필요한 원소인 음소, 으절, 단어를 인식해내는 역할을 하고 있다.
(이를 위해 음성학, 음운학, 음운 배열론, 시형론 요구)
- 알고리즘 별 접근 방식
DTW : 동적 프로그래밍을 통한 접근
HMM : 확률추정을 통한 접근
Knowledge Base : 인공지능을 이용한 추론을 통한 접근
Neural Network : 패턴분류를 통한 접근
    - 후처리
패턴 인식 결과인 음소, 음절, 단어를 재구성해서 문장을 복원한다.
(이를 위해 구문론, 의미론, 어형론이 이용된다.)
구문규칙 모델(syntactic): 매 단어 다음에 올 수 있는 단어의 종류를 제한해 문장을 구성
통계적 모델(statistical) : 매 단어에 대해 이전의 N개의 단어가 발생할 확률을 고려해 문장을 인식
```

#### 2-2 음성인식 시스템 판정기준

```
판정 기준
1. 화자와 독립적인지
2. 연속단어를 처리할수 있는지
3. 처리 단어 수는 얼마나 되는지

    - 화자와 독립 or 종속 적인지
말하는 사람이 달라져도 그대로 기능을 수행할 수 있는지 확인하는 것.
화자 종속(Speaker dependent)인 시스템보다 화자가 달라도 인식 할 수 있는 화자독립(Speaker independent)일 때 더 발전된 시스템
    - 연속단어를 처리할수 있는지
고립 단어 or 연속 단어 의 의도적인 연속적 묶음이 있어야 인식할 수 있는지,
일상생활에서의 연속적인 대화에서도 기능을 수행할 수 있는지 확인하는것
    - 처리 단어 수
얼마나 다양한 단어를 인식할 수 있는지.
    - 이 외
인식률 - 얼마나 정확하게 음성을 인식하는지
잡음의 처리정도
```

#### 2-3 음성인식의 어려움

```
음성데이터는 변화가 큰 데이터.
발화 기관의 상태, 음소, 음운의 문장 내 위치에 따라큰 변동성을 보인다.
    - 음운 변화의 요인 발화 기관에 영향을 미치는 외재적 요인
음운 표현 길이 와 크기, 발화자의 신체적 감서정적 상태와 주변 요인에 큰 영향을 받는다.
악센트, 억양, 리듬, 목소리의 크기, 잡음 등에 따라서도 음운이 다양한 변주를 일으킨다.
사투리 표준어등의 차이도 있음.
- 보안 요소
데이터의 전처리 방법과 패턴 인식부분을 정밀하게 한다.
발화자 이외의 음운 성분을 제거하는 기술 필요
     - 음운 변화의 요인 발화 기관에 영향을 미치는 내재적 요인
음운 규칙은 크게 자생적 변동, 결합적 변동으로 나눌 수 있고, 결합적 변동은 다시 결정적 변동과 수의적 변동으로 나눌 수 있다. 
- 보안 요소
발화 현상에 대한 다양한 조음 규칙을 적용 (궁극적인 해결책은 아님)
-> 머신러닝을 통한 해결
```

## 3. 음성인식 관련 알고리즘

#### 3-1. 퍼지이론

```
    - 퍼지 이론
확률 이론과 이치 논리의 결합
어떤 속성을 나타내는 집합을 설정하고 어떤 원소들이 이 집합에 속하는 정도를 0~1 사값으로 나타내는 것
-> 크다 - 작다, 긍정 - 부정 으로 나누는 것이 아닌 애매모호한 사실을 나타내기 위함

    - 집합 과 퍼지
- 집합
집합의 관점에서 원소들이 자기 자신에게 어느 정도 포합되는지 표현
- 퍼지
원소의 관점에서 보았을 때 자기 자신이 어떤 집합에 어느 정도로 포함되는지를 표현

    - 퍼지 개념 과 신경망
- 신경망
애매모호한 개념을 표현하기 위한 것
- 신경망
주어진 데이터로부터 스스로 배워 일반적을 특징을 끄집어 내는것
```

#### 3-2. 시뮬레이티드 어닐링

```
1983년 패트릭에 의해 물체구조의 상태를 연구하다가 발명됨.

고온 상태의 물체를 어느 속도로 식히냐에 따라 각기 다른 에너지를 갖는 최종 결정 상태가 다르게 결정됨
-> 이 현상을 통해 함수의 초소값을 결정할 수 있는 최적화 알고리즘을 발명 
```

#### 3-3 유전 알고리즘(Genetic Algorithm)

```
1975년 홀란드는 생물의 진화 메커니즘을 연구하다가 유전 알고리즘을 고안

진화론처럼 현 세대(generation)의 인구(population) 중에서 좋은 형질(fitness)을 지니고 있는 인류가 
다음 세대에게 유전자를 물려줄 수 있는 부모(parents)가 될 기회를 갖게 되고 좋지 못한 형질을 지니고 있는 개체는 이후 세대에서 사라지게 된다. 
우리가 흔히 알고 있는 교배(mating), 돌연변이(mutation) 등을 수학적으로 표현하였고 결국 최고(best)의 인구(population)를 갖게되는 최적화 알고리즘
    
    - 시뮬레이티드 어닐링 과 유전 알고리즘
- 시뮬레이티드 어닐링
물질상태가 이론의 배경
- 유전 알고리즘
생채진화가 이론의 배경
```

#### 4-1 인간의 음파 수용 메커니즘

```
사람의 청각 기관은 음성, 음악 소리, 배경 소리와 같은 외계 정보를 음파의 형태로 받아들인다. 
- 음파
청각 기관을 거치면서 공기 매질과 액체 매질을 통과하는 밀도파로 진행
- 밀도파
내이의 말단부인 코르티 기관에 이르러 전기 신호의 형태로 변환된 후, 청신경을 타고 가다 뇌 측두엽에 전달되면서 비로소 정보의 처리가 진행


청각 기관인 두 귀는 얼굴을 정면에서 보면 서로 가장 멀리 떨어진 곳에 자리잡고 있다.
-> 두 귀에 도달하는 음파의 강도와 도착 시간이 달라, 음파의 발생 방향, 위치를 찾기 유리

두 귀는 외이, 중이, 내이의 세부분으로 이루어져 있다.
```

- 외이

```
귓바퀴와 외이도로 구성되어있다.
    - 귓바퀴
깔때기 모양으로 소리를 모으는 기능
귓바퀴에 모아진 소리는 외이도를 따라 고막으로 진행한다.
   - 외이도
전체적으로 구부러진 모양
-> 시끄러운 소리로부터 직접적인 피래를 입지 않도록 막아주거나 벌레 등의 침입을 막는데 유리

외이의 긴 간 구조는 고명 형상을 통한 필터링 기능과 연관이 있다.
즉, 귓바퀴는 열려 있는 반면 고막 쪽은 닫혀 있는 형태의 관악기 모양이므로 공명 현상을 일으켜 특정 주파수의 이득을 볼 수 있다.
일반적으로 공명 주파수는 귓바퀴에서 약 5.5 kHz, 10 ~ 15 dB의 이득을 보고 있고, 외이도에서는 약 2.5kHz, 이득은 15~20 dB의 이득이 있다고 한다.
```

- 중이

```
청각 기관 중 고막부터 등자뼈 발판까지의 범위
세개의 이소골이 있는데, 각각 망치뼈(추골), 모루뼈(침골), 등자뼈(등자뼈)로 부른다.
음파가 외이도를 지나 고막을 진동시키면, 이소골은 고막의 진동을 기계적인 에너지로 변환하여 내이로 전달
이소골에 붙은 작은 근육은 저음 영역의 강한 소리로 인해 내이가 손상되는것을 막아준다.

외이와 중이 영역까지 은파는 공기 매질을 통해 전달되며, 내이부터는 림프액이라는 액체를 통해 음파가 전달
공기와 액체라는 서로 다른 매질로 인해 음파가 반사되거나 소실 될 수 있기 때문에, 이를 극복하기 위해 음압을 증폭시킬 필요가 있는데, 중이가 이러한 역할

    - 음파 증가
고막이 원뿔 모양이어서 원뿔 꼭지점 부분에 집중된 음압이 망치뼈로 전달되면서 음압이 2~3배 증가한다. 
고막과 등자뼈 발판은 그 면적비가 약 17:1이기 때문에 음압은 17배 가량 증가하고 이는 25 dB 만큼 음압이 증폭되는 효과를 낸다. 
또한 망치뼈와 모루뼈의 길이가 1.3:1로 이에 따라 음압은 약 2dB 정도 증폭된다. 
이 세 효과를 합치면 중이를 거치면서 음파는 대략 33 dB만큼 증폭되는 것으로 알려져 있다
```

- 내이

```
평형 감각을 담당하는 전정 기관의 세반고리관과 청각 기관인 달팽이관으로 이루어져 있다.
    - 달팽이관
약 2.75바퀴의 회전을 보이는 두 개의 나선형 터널 길이는 약 35 mm 이다.
두 터널은 뼈로 둘러싸여 있으며 내부는 림프액이 차 있다.
 
달팽이관의 기저부(base)는 넓고 첨단부(apex)는 좁은 구조이다. 
이에 따라 기저부는 높은 공명 주파수를 감지하고, 첨단부는 낮은 공명 주파수를 감지할 수 있다. 
```

## 5. 음성인식 역사

```
    - 1950,60 년대
첫 음성인식은 숫자만 인식
1952년에 Bell은 “Audrey”라는 시스템을 만들었고, 이 시스템은 하나의 숫자를 말하면 이를 인식할 수 있다.
-> 10년 후 IBM은 "Shoebox" 시템을 선보임 16가지 영단어 인식
이후 미국, 일본, 영국, 소련 등에서 4개의 모음, 9개의 자음을 지원 할 수 있게 확장

    - 1970 년대
U.S. Department of Defence의 관심과 지원으로 1970년대에 큰 도약을 이룸
DoD의 DARPA 음성인식연구 프로그램은 음성인식 역사상 가장 큰 이슈 중 하나
->  Carnegie의 “Harpy” 시스템에 쓰였다. Harpy는 1011개의 단어를 인식 (3살 정도의 어휘력)
hreshold Technolgy라는 첫 상업적인 음성인식 회사가 설립되었고 Bell의 연구소는 여러명의 목소리를 해석 

    - 1980 년대
Hidden Markov Model 이라는 통계적인 방법론을 새롭게 접근하며 음성인식 가능한 어휘는 수백개에서 수천개로 급등
HMM은 단순히 단어 템플릿, 소리 패턴을 찾는 것이 아니라 모르는 소리가 단어가 될 확률을 고려(20년 후에도 사용 중)
-> 그러나 매 단어 다음마다 멈춰야 가능

    - 1990 년대
컴퓨터의 발전에 따른 일반인의 음성인식 소프트웨어 접근
Dragon은 첫 소비자용 음성인식 제품을 출시

    - 2000 년대
2001년까지 컴퓨터 음성인식은 80% 정확도에서 보합세를 보였고 2000년 후반에는 기술 발전이 정지된것처럼 보였다.
```


- 참고 문헌 <br>

url : https://wikidocs.net/30702




















