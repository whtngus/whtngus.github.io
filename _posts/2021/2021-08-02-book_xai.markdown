---
layout: post
title: "book : XAI 설명 가능한 인고지능, 인공지능을 해부하다."
date: 2021-08-09 19:20:23 +0900
category: book
---

# 책 제목 :  XAI 설명 가능한 인고지능, 인공지능을 해부하다.

예제 코드 다운로드 : https://github.com/wikibook/xai



# 5장 대리분석

## 5.1 대리 분석 기법(Surrogate Analysis)

엔지니어링에 사용되던 용어

본래 기능을 흉내 내는 간단하 대체재를 만들어 프로타입이 동작하는지 판단하는 분석 방법

XAI에서는 유사한 기능을 흉내 내는 여러개의 모델을 대리로 만들어 본래 모델을 분석하는 방법

여러 이름으로 불림 - Approximation model, Response Suface Model, Evulator등 

대리 분석 기법은 model-agnostic technology하다. (모델에 대한 지식 없이도 학습할 수 있음)



### 글로벌 대리 분석(Global Surrogate)

학습 데이터를 사용해 유사함수를 만들고 유사함수를 해석 가능하도록 변조하는 방법

전통적인 머신러닝 기법에 적용하기 좋다.

### 로컬 대리 분석(Local Surrogate)

데이터 하나에 대해 블랙박스가 해석하는 과정을 분석하는 기법

LIME(Local Interpretable Model)로도 불림

-> 모델이 현재 데이터의 어떤 영역을 집중해서 분석했고 어떤 영역을 분류 근거로 했는지 알려주는 XAI기법

- 원리

> 입력 데이터에 대해 부분적으로 변화를 줘 중요한 부분을 찾는 방식
>
> -> 변형(perturbation) 혹은 샘플퍼뮤테이션(sample permutation)이라고 함 

- LIME의 장단점

> 1. 모델에 관계없이 적용 가능 
> 2. 매트릭스로 표현 가능한 데이터에 대해 작동하는 XAI(이미지, 텍스트)
> 3. 매우 가벼운 모델 

## 5.3 SHAP(SHapley additive exPlanations)

로이드 섀플리(Lloyd Stowell Shapley)가 만든 이론 위에 피처 간 독립성을 근거로 덧셈이 가능하게 화용도를 넓힌 논문

- Shapley value(섀플리 값)

전체 성과를 창출하는데 각 참여자가 얼마나 공헌했는지를 수치로 표현 

-> 각 사람의 기여도 = 전체 기여도 - 그사람이 없을 때 기여도

(섀플리 값은 음수일수도 있으며 이는 부정적인 값을 의미)



# 6. 필터 시각화(Filter Visualization)

## 6.1 이미지 필터 시각화

학습된 신경망 모델에 이미지가 입력됐을때 각 은닉 계층마다 인풋 이미지에 어떻게 반응했는지 시각적으로 확인하는기법

CNN Layer에서 처음과 두번째 통과한 필터는 어느정도 시각화된 직관적인 이해가 가능하다.

## 6.2 설명 가능한 모델 결합하기

학습이 끝난 신경망이 어떤 입력에 대해 지속해서 검은 필터 결과를 출력한다면 이 신경망이 잘못된 loss function 때문에 학습이 잘 이뤄지지 않았다고 유추할 수 있다.

- CNN과  필터

> - 필터(filter or kernel)
>
> 원본 데이터를 해석하기 위해 사용하는 일정한 행렬값
>
> - Convolution Layer
>
> 입력 데이터로부터 특정 요소만을 추출
>
> 입력 행렬에 필터를 곱하는 방식
>
> - Polling Layer
>
> '통합'이라는 의미로 구획을 가장 잘 표현할 수 있는 대푯값
>
> - CNN Layer
>
> 위 계층들을 조합한 네트워크

## 6.4 합성곱 신경망 시각화

CNN의 첫벗째 레이어의 필터의값들을 받아 시각화를 처리 (이후 layer는 시각적으로 보기 힘들어 직관적인 이해하기가 어렵기 때문에 )



필터 시각화기법은 XAI 기법 중에서도 이미지 딥러닝 계열에 강력한 도구

단점은 필터시각화를 위해 은닉층을 2차원으로 고정해야함 (CNN은 3차원이 되는 경우도 많아서 불편)

