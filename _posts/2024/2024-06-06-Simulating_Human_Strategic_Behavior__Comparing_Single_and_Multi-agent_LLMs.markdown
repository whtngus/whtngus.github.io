---
layout: post
title: "Simulating Human Strategic Behavior: Comparing Single and Multi-agent LLMs"
date: 2024-06-06 02:05:23 +0900
category: paper
---



# Simulating Human Strategic Behavior: Comparing Single and Multi-agent LLMs

Columbia University, USA

2024년 2월 13일 아카이빙



# Abstract

계획을 세우거나 행동을 할때 사람의 행동을 전략적으로 파악하기는 어려움 

 최근 llm이 등장하면서 사람을 시뮬레이션 할 수 있을정도의 성능의 모델이 나오기 시작함 

해당 논문에서는 LLM이 인간의 전략적 행동을 시뮬레이션할 수 있는지 조사함 

논문에서는 최후통첩 게임을 통해 사람의 행동을 이해하는 연구를 함 

1. 최후통첩에서 사람과 비슷한 행동을 하는 행동을 비교
2. 두 플레이어 간의 탐욕과 공정한 성격을 시뮬레이션 
3. 논리적으로 완벽한 전략과 성격을 생성하는 능력을 평가함 

사람의 전략과 성격 쌍에 대해 행동 시뮬레이션이 더 정확하다고함 (88% vs 50%)

-> 자세한 내용은 아래 내용 보면서 확인 



이를통해 계획자와 정책 입안자 등 시스템에서 사람들이 어떻게 행동할지를 예비적으로 참구할 수 있음 



# 1 INTRODUCTION

시뮬레이션은 빌딩의 지진안전 설계, 계획을 평가, 경제 정책 등 많은 부분에서 도움을 줄 수 있음 

논문에서 물리적 시뮬레이션은 많이 발전했지만 사람의 행동을 시뮬레이션하는건 악명 높을정도로 어렵다고 함

 최근 LLM은 사람의 페르소나를 시뮬레이션 할 수 있는것으로 나타났으며 과거 대법관들의 판결을 모방하기도 했음 

논문에서는  LLM simulations 실험을 통해 사람의 행동 전략에 대해 영구함 

최후통첩은 사람의 사회적인 행동을 알 수 있는 기본적인 경제학 실험임 



두 플레이어가 제안자와 수신자로 나뉘어서 게임을 진행

제안자에게 먼저 특정 양의 돈이 주어짐 (ex 1$)

그리고 수신자에게 얼마를 나누어 줄지를 결정함 

수신자는 동의하거나 거절할 수 있으며  동의시 돈을 나눠서 받으며 거절시 두 플레이어는 아무돈도 받지 못함

 

경제학 이론에 따르면 가장 합리적인 최대 배분 값은 0.01$라고 함 

-> 나눌 수 있는 최솟값 이기 때문에, 그리고 수신자는 비동의하면 아무것도 받지 못하기때문에 무조건 동의해야함

그러나 실험적으로 사람은 관계적인 행동을 함 그리고 수신자는 공평하지 않은 돈을 제안하면 벌을 주기 위해 거절하기도 함  -> 제안자는 이를 알기때문에 공평함과 가까운 돈을 주는 전략을 세워야함 



40번의 시뮬레이션에서 Multi-agent 구조로 사람의 행동 88%정도가 일치했으며 LLM의 행동 50%가 일치함 

LLM과 인간의 행동이 일치하지 않는 이유는 아래와 같다.

1. 생선된 전략이 불완전함 
2. 생성된 전략이 지정된 성격과 일치하지 않음 
3. 플에이어가 게임 플레이 중에 생성된 전략에서 벗어난다.



총 40번의 시뮬레이션에서 1번만 오류가 플레이어가 생성된 전략을 따르지 않아서 문제가 발생함 



# 2. RELATED WORK

## 2.1 Ultimatum Game Background and Experiments

McCabe(2014)에 따르면 제안자들은 40% 또는 50%를 제안한경우 수락하지만 제안 금액이 20%일때 50%까지 하락하고 10%는 더 많이 하락한다고 한다.



## 2.2 LLM Reasoning

ext-davinci-003. 모델을 사용 나머지는 간단해서 생략

## 2.3 Using LLMs to Simulate Strategic Behavior

생략

## 2.4 Multi-Agent Paradigms of LLMs

기존 게임 시뮬레이션에서 단일 LLM을 사용했지만 새로운 에이전트 기반 구조는 사람의 행동을 더욱 효과적으로 예측할 수 있음 

아키텍처는 자기 지식, 기억, 계획, 반응, 성찰 다섯가지 구성요소를 포함함 

# 3 EXPERIMENTAL SET-UP

최후통첩 게임에서 llm이 사람의 행동을 시뮬레이션할 수 있는지를 테스트하기 위해 5라운드의 게임을 진행함 

이때 단일 llm과 멀티 에이전트 llm 기반의 아키텍처로 구성됨 

단일 llm은 프롬프트로 각각의 플레이어의 전략을 생성하고 실행을 함 

멀티 에이전트 llm은 각각의 플레이어를 각각 llm이 담당함 



탐욕, 공평한 두개의 성격을 테스트함 

단일 다중 에이전트에 대해 40개이ㅡ 시뮬레이션을 진행 (각 성격상 10개씩 단일 다중 진행함)



실험에서 GPT3.5, GPT4를 둘다 사용함

## 3.1 Research Questions

RQ1. 최후통첨 5라운드 동안 LLM이 사람과 비슷하게 행동할 수 있는가

RQ2. LLM이 사람의 성격을 그대로 모사할 수 있느가

RQ3. LLM이 최적화된 전략을 만들 수있는가 



단일 다중 에이전트는 각각의 장단점이 있다고 함 

single LLMs :  LLM이 모든 플레이어에 대한 모든 기록을 가지고 있음  -> 일관성 있는 게임을 진행 함 

Multi-agent : global context는 없지만 하나의 agent를 충분히 이해하고 선택할 수 있음 

## 3.2 Single LLM and Multi-Agent Architecture

### 3.2.1 Inputs

single-LLM structure

1. 5라운드 동안 각 플레이어들에게 최후통첩 게임 전략을 생성하고 표시함
2. 설정된 전략에따라 5라운드 동안 게임을 진행함

수령인은 제안자가 제안한 경우에만 판단 

 프롬프트 디자인에서는 원하는 행동을 생성하는 가장 간단한 프롬프트를 목표로 함

### 3.2.2 Outputs

![f_1](F:\code\whtngus.github.io\img\2024\Simulating_Human_Strategic_Behavior__Comparing_Single_and_Multi-agent_LLMs\f_1.PNG)

그림 1과 같이 제안자가 제안을하고 수신자가 제안을 받거나 거절하는 방식으로 진행이됨 

다중 에이전트는 별돌의 행동이 기록됨 ->  여러 가능한 전략을 고려한 후 하나의 전략을 선택하거나 여러 전략을 결합하여 메모리에 기록

제안자는  제안을 통해 수락을 계속 받으면 가격을 낮춰서 제안하는 방식

## 3.3 Evaluation

### 3.3.1 Evaluation of Gameplay





 

















